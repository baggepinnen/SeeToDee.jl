var documenterSearchIndex = {"docs":
[{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/#Docstrings","page":"API","title":"Docstrings","text":"","category":"section"},{"location":"api/#Integrators","page":"API","title":"Integrators","text":"","category":"section"},{"location":"api/#SeeToDee.Rk4","page":"API","title":"SeeToDee.Rk4","text":"f_discrete = Rk4(f, Ts; supersample = 1)\n\nDiscretize a continuous-time dynamics function f using RK4 with sample time Tₛ.  f is assumed to have the signature f : (x,u,p,t)->ẋ and the returned function f_discrete : (x,u,p,t)->x(t+Tₛ).\n\nsupersample determines the number of internal steps, 1 is often sufficient, but this can be increased to make the integration more accurate. u is assumed constant during all steps.\n\nIf called with StaticArrays, this integrator is allocation free.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.Rk3","page":"API","title":"SeeToDee.Rk3","text":"f_discrete = Rk3(f, Ts; supersample = 1)\n\nDiscretize a continuous-time dynamics function f using RK3 with sample time Tₛ. f is assumed to have the signature f : (x,u,p,t)->ẋ and the returned function f_discrete : (x,u,p,t)->x(t+Tₛ).\n\nsupersample determines the number of internal steps, 1 is often sufficient, but this can be increased to make the integration more accurate. u is assumed constant during all steps.\n\nIf called with StaticArrays, this integrator is allocation free.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.Heun","page":"API","title":"SeeToDee.Heun","text":"f_discrete = Heun(f, Ts; supersample = 1)\n\nDiscretize a continuous-time dynamics function f using Heun's method with sample time Tₛ. f is assumed to have the signature f : (x,u,p,t)->ẋ and the returned function f_discrete : (x,u,p,t)->x(t+Tₛ).\n\nsupersample determines the number of internal steps, this can be increased to make the integration more accurate, but it might be favorable to choose a higher-order method instead. u is assumed constant during all steps.\n\nIf called with StaticArrays, this integrator is allocation free.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.ForwardEuler","page":"API","title":"SeeToDee.ForwardEuler","text":"f_discrete = ForwardEuler(f, Ts; supersample = 1)\n\nDiscretize a continuous-time dynamics function f using forward Euler with sample time Tₛ.  f is assumed to have the signature f : (x,u,p,t)->ẋ and the returned function f_discrete : (x,u,p,t)->x(t+Tₛ).\n\nsupersample determines the number of internal steps, this can be increased to make the integration more accurate, but it might be favorable to choose a higher-order method instead. u is assumed constant during all steps.\n\nIf called with StaticArrays, this integrator is allocation free.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.SimpleColloc","page":"API","title":"SeeToDee.SimpleColloc","text":"SimpleColloc(dyn, Ts, nx, na, nu; n = 5, abstol = 1.0e-8, solver=SimpleNewtonRaphson(), residual=false)\nSimpleColloc(dyn, Ts, x_inds, a_inds, nu; n = 5, abstol = 1.0e-8, solver=SimpleNewtonRaphson(), residual=false)\n\nA simple direct-collocation integrator that can be stepped manually, similar to the function returned by SeeToDee.Rk4.\n\nThis integrator supports differential-algebraic equations (DAE), the dynamics is expected to be on either of the forms \n\nnx,na provided: (xz,u,p,t)->[ẋ; res] where xz is a vector [x; z] contaning the differential state x and the algebraic variables z in this order. res is the algebraic residuals, and u is the control input. The algebraic residuals are thus assumed to be the last na elements of of the arrays returned by the dynamics (the convention used by ModelingToolkit).\nx_inds, a_inds provided: (xz,u,p,t)->xzd where xzd[x_inds] = ẋ and xzd[a_inds] = res.\n\nThe returned function has the signature f_discrete : (x,u,p,t)->x(t+Tₛ). \n\nThis integrator also supports a fully implicit form of the dynamics\n\n0 = F(x x u p t)\n\nWhen using this interface, the dynamics is called using an additional input ẋ as the first argument, and the return value is expected to be the residual of the entire state descriptor. To use the implicit form, pass residual = true.\n\nA Gauss-Radau collocation method is used to discretize the dynamics. The resulting nonlinear problem is solved using (by default) a Newton-Raphson method. This method handles stiff dynamics.\n\nArguments:\n\ndyn: Dynamics function (continuous time)\nTs: Sample time\nnx: Number of differential state variables\nna: Number of algebraic variables\nx_inds, a_inds: If indices are provided instead of nx and na, the mass matrix is assumed to be diagonal, with ones located at x_inds and zeros at a_inds. For maximum efficiency, provide these indices as unit ranges or static arrays.\nnu: Number of inputs\nn: Number of collocation points. n=2 corresponds to trapezoidal integration.\nabstol: Tolerance for the root finding algorithm\nresidual: If true the dynamics function is assumed to return the residual of the entire state descriptor and have the signature (ẋ, x, u, p, t) -> res. This is sometimes called \"fully implicit form\".\nsolver: Any compatible SciML Nonlinear solver to use for the root finding problem\nscale_x: If provided, the state variables are scaled by this vector before being passed to the nonlinear solver. This can improve convergence for states with very different magnitudes. The scaling is applied as res .= res ./ scale_x before being passed to the solver.\n\nExtended help\n\nSuper-sampling is not supported by this integrator, but you can trivially wrap it in a function that does super-sampling by stepping supersample times in a loop with the same input and sample time Ts / supersample.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.Trapezoidal","page":"API","title":"SeeToDee.Trapezoidal","text":"Trapezoidal(dyn, Ts, nx, na, nu; abstol = 1.0e-8, solver=SimpleNewtonRaphson(), residual=false)\nTrapezoidal(dyn, Ts, x_inds, a_inds, nu; abstol = 1.0e-8, solver=SimpleNewtonRaphson(), residual=false)\n\nA simple trapezoidal integrator that can be stepped manually, similar to the function returned by SeeToDee.Rk4.\n\nThis integrator supports differential-algebraic equations (DAE), the dynamics is expected to be on either of the forms \n\nnx,na provided: (xz,u,p,t)->[ẋ; res] where xz is a vector [x; z] contaning the differential state x and the algebraic variables z in this order. res is the algebraic residuals, and u is the control input. The algebraic residuals are thus assumed to be the last na elements of of the arrays returned by the dynamics (the convention used by ModelingToolkit).\nx_inds, a_inds provided: (xz,u,p,t)->xzd where xzd[x_inds] = ẋ and xzd[a_inds] = res.\n\nThe returned function has the signature f_discrete : (x,u,p,t)->x(t+Tₛ). \n\nArguments:\n\ndyn: Dynamics function (continuous time)\nTs: Sample time\nnx: Number of differential state variables\nna: Number of algebraic variables\nx_inds, a_inds: If indices are provided instead of nx and na, the mass matrix is assumed to be diagonal, with ones located at x_inds and zeros at a_inds. For maximum efficiency, provide these indices as unit ranges or static arrays.\nnu: Number of inputs\nabstol: Tolerance for the root finding algorithm\nresidual: If true the dynamics function is assumed to return the residual of the entire state descriptor and have the signature (ẋ, x, u, p, t) -> res. This is sometimes called \"fully implicit form\".\nsolver: Any compatible SciML Nonlinear solver to use for the root finding problem\nscale_x: If provided, the residual is scaled by this vector before being passed to the nonlinear solver, res ./ scale_x. This can help with convergence if the state variables have very different magnitudes.\n\nExtended help\n\nSuper-sampling is not supported by this integrator, but you can trivially wrap it in a function that does super-sampling by stepping supersample times in a loop with the same input and sample time Ts / supersample.\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.AdaptiveStep","page":"API","title":"SeeToDee.AdaptiveStep","text":"AdaptiveStep(integrator)\n\nA wrapper that enables automatic step subdivision for taking arbitrary-length steps with any integrator.\n\nWhen the requested step size Ts is larger than the integrator's effective step size (largest_Ts),  AdaptiveStep automatically subdivides the step using the integrator's internal supersample mechanism  (for explicit integrators) or manual stepping (for implicit integrators).\n\nFields\n\ninteg: The wrapped integrator\nlargest_Ts: The largest step size the integrator can take in a single call (Ts / supersample)\n\nUsage\n\n# Wrap any integrator to enable automatic step subdivision\nbase_integrator = Rk4(dynamics, 0.1; supersample=2)  # largest_Ts = 0.05\nadaptive_integrator = AdaptiveStep(base_integrator)\n\n# Take arbitrary step sizes - automatically subdivides when needed\nx_next = adaptive_integrator(x, u, p, t; Ts=0.3)  # Uses supersample=6 internally\n\nNotes\n\nThis wrapper does NOT use error control - it only ensures step sizes never exceed largest_Ts\nFor explicit integrators (Rk4, Rk3, ForwardEuler, Heun), uses built-in supersample mechanism\nFor implicit integrators (SimpleColloc, Trapezoidal), performs manual step subdivision\nWhen Ts ≤ largest_Ts, calls the integrator directly without subdivision\n\nExamples\n\nusing SeeToDee, StaticArrays\n\n# Define dynamics\nfunction simple_dynamics(x, u, p, t)\n    return -x + u\nend\n\n# Create base integrator with supersample=3\nbase = SeeToDee.Rk4(simple_dynamics, 0.1; supersample=3)  # largest_Ts = 0.1/3 ≈ 0.033\n\n# Wrap with AdaptiveStep\nadaptive = SeeToDee.AdaptiveStep(base)\n\nx0 = SA[1.0]\nu = SA[0.5]\n\n# Small step - no subdivision needed\nx1 = adaptive(x0, u, 0, 0; Ts=0.02)  # Direct call\n\n# Large step - automatic subdivision\nx2 = adaptive(x0, u, 0, 0; Ts=0.5)   # Uses supersample=15 internally\n\n\n\n\n\n","category":"type"},{"location":"api/#SeeToDee.SwitchingIntegrator","page":"API","title":"SeeToDee.SwitchingIntegrator","text":"SwitchingIntegrator(int_true, int_false, cond)\n\nCreate an integrator that switches between two different integrators based on a condition.\n\nint_true: Integrator to use when cond(...) is true\nint_false: Integrator to use when cond(...) is false\ncond: A function that takes the same arguments as the integrator and returns a Bool\n\nThis can be used to, e.g., use a faster integrator when the state is in a certain region and a more accurate (but slower) integrator otherwise.\n\n\n\n\n\n","category":"type"},{"location":"api/#Utilities","page":"API","title":"Utilities","text":"","category":"section"},{"location":"api/#SeeToDee.linearize","page":"API","title":"SeeToDee.linearize","text":"A,B = linearize(f, x0, u0, p, t)\n\nLinearize dynamics function f(x, u, p, t) w.r.t., state x, input u. Returns Jacobians A,B in\n\nx = A Δx + B Δu\n\nWorks for both continuous and discrete-time dynamics.\n\n\n\n\n\n","category":"function"},{"location":"api/#SeeToDee.initialize","page":"API","title":"SeeToDee.initialize","text":"initialize(integ, x0, u, p, t = 0.0; solver=integ.solver, abstol=integ.abstol)\n\nGiven the differential state variables in x0, initialize the algebraic variables by solving the nonlinear problem f(x,u,p,t) = 0 using the provided solver.\n\nArguments:\n\ninteg: An intergrator like SeeToDee.SimpleColloc\nx0: Initial state descriptor (differential and algebraic variables, where the algebraic variables comes last)\n\n\n\n\n\n","category":"function"},{"location":"#SeeToDee","page":"Home","title":"SeeToDee","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Build Status)","category":"page"},{"location":"","page":"Home","title":"Home","text":"SeeToDee implements low-overhead, nonlinear variants of the classical c2d function from ControlSystems.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given a continuous-time dynamics function","category":"page"},{"location":"","page":"Home","title":"Home","text":"dot x = f(x u p t)","category":"page"},{"location":"","page":"Home","title":"Home","text":"this package contains integrators that convert the continuous-time dynamics into a discrete-time dynamics function","category":"page"},{"location":"","page":"Home","title":"Home","text":"x_t+T_s = f(x_t u_t p t)","category":"page"},{"location":"","page":"Home","title":"Home","text":"that advances the state from time t to time t+T_s, with a Zero-order-Hold (ZoH) assumption on the input u.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The integrators in this package focus on","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inputs are first class, i.e., the signature of the dynamics take input signals (such as control signals or disturbance inputs) as arguments. This is in contrast to the DifferentialEquations ecosystem, where there are several different ways of handling inputs, none of which are quite first class.\nLow overhead for single-step integration, i.e., no solution handling, no interpolation, nothing fancy at all.\nFixed time step. All integrators are non-adaptive, i.e., the integrators do not change their step size using error control. This typically makes the integrator have a more predictable runtime. It also reduces overhead without affecting accuracy in situations when the fixed step-size is small in relation to what would be required to meet the desired accuracy, a situation which is common when simulating control systems. It also means that the user is responsible for checking the accuracy for the chosen step size.\nDirt-simple interface, i.e., you literally use the integrator as a function x⁺ = f(x, u, p, t) that you can call in a loop etc. to perform simulations.\nMost things are manual. Want to simulate a trajectory? Write a loop!","category":"page"},{"location":"#Available-discretization-methods","page":"Home","title":"Available discretization methods","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The following methods are available","category":"page"},{"location":"","page":"Home","title":"Home","text":"SeeToDee.Rk4 An explicit 4th order Runge-Kutta integrator with ZoH input. Supports non-stiff differential equations only. If called with StaticArrays, this method is allocation free.\nSeeToDee.Rk3 An explicit 3rd order Runge-Kutta integrator with ZoH input. Supports non-stiff differential equations only. If called with StaticArrays, this method is allocation free.\nSeeToDee.Heun An explicit 2nd order Runge-Kutta integrator with ZoH input. Supports non-stiff differential equations only. If called with StaticArrays, this method is allocation free.\nSeeToDee.ForwardEuler An explicit 1st order Runge-Kutta integrator with ZoH input. Supports non-stiff differential equations only. If called with StaticArrays, this method is allocation free.\nSeeToDee.SimpleColloc A textbook implementation of a direct collocation method with ZoH input. Supports stiff differential-algebraic equations (DAE) and fully implicit form 0 = F(x x u p t).\nSeeToDee.Trapezoidal Trapezoidal integration with ZoH input. Supports stiff differential-algebraic equations (DAE).\nSeeToDee.AdaptiveStep A wrapper that enables automatic step subdivision for taking arbitrary-length steps with any integrator. Note: this does not use error control, it only makes sure that the step size never exceeds that of the base integrator, Ts / supersample.\nSeeToDee.SwitchingIntegrator A wrapper that switches between two different integrators based on a user-defined condition. Useful for adaptive selection of integration methods based on state, time, or parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"See their docstrings for more details.","category":"page"},{"location":"#When-is-this-package-useful?","page":"Home","title":"When is this package useful?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Control systems are most of the time implemented in discrete time a computer, but they may interact with the continuous-time world around them. Simulation of the combined system including both the discrete-time controller and the continuous-time world is therefore a common task. The typically fixed sample interval of the controller, T_s, is thus presenting an upper bound to the length of the integration step in the simulation, an adaptive solver cannot take longer steps than this since the input is discountinuous with the invocation of the controller. If the sample time is short, a good adaptive algorithm will thus always take a step of length T_s, but figuring this out incurs unnecessary overhead. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The invocation of the controller also means that some additional code, the implementation of the controller, has to be run at a fixed interval, but not in-between. The DifferentialEquations ecosystem provides callbacks for this purpose. Making use of the callback is associated with a very large amount of boilerplate already for simple control-system simulations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"It's also common to want to do more than just simulation, for example, linearize the dynamics or state estimation. In both of those cases, one may be interested in integrating a single step of length T_s only, starting from an arbitrary initial condition. In such situations, a one-liner function call is then preferable to a 10+ lines configuration of a traditional ODE solver, combined with the appropriate calls to remake etc. in-between calls.","category":"page"},{"location":"#When-should-you-not-use-this-package?","page":"Home","title":"When should you not use this package?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If inputs that change at a fixed interval is not an integral part of your dynamics.\nYour system requires a very special integrator for simulation.\nYour system is very large, e.g., a discretized PDE.\nIf the sample interval T_s is long in relation to the time constants of the system, then an adaptive solver may be more efficient despite the discontinuities.","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The example below defines a dynamics function cartpole and then discretizes this using SeeToDee.Rk4 and propagates the state forward one time step","category":"page"},{"location":"","page":"Home","title":"Home","text":"using SeeToDee, StaticArrays\n\nfunction cartpole(x, u, p, t)\n    T = promote_type(eltype(x), eltype(u))\n    mc, mp, l, g = p\n\n    q  = x[SA[1, 2]]\n    qd = x[SA[3, 4]]\n\n    s = sin(q[2])\n    c = cos(q[2])\n\n    H = @SMatrix [mc+mp mp*l*c; mp*l*c mp*l^2]\n    C = @SMatrix [0 -mp*qd[2]*l*s; 0 0]\n    G = @SVector [0, mp * g * l * s]\n    B = @SVector [1, 0]\n    qdd = -H \\ (C * qd + G - B * u[1])\n    return [qd; qdd]\nend\n\nTs = 0.01\ndiscrete_dynamics_rk = SeeToDee.Rk4(cartpole, Ts; supersample=2)\n\nx0 = SA[1.0, 2.0, 3.0, 4.0]\nu0 = SA[1.0]\np = mc, mp, l, g = 1.0, 0.2, 0.5, 9.81\n\nx1_rk4 = discrete_dynamics_rk(x0, u0, p, 0)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function discrete_dynamics_rk is now the discretized dynamics x^+ = f(x u p t), and x1_rk4 is the state at time 0+T_s. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next, we do the same but with SeeToDee.SimpleColloc instead of SeeToDee.Rk4.","category":"page"},{"location":"","page":"Home","title":"Home","text":"n  = 5 # Number of collocation points\nnx = 4 # Number of differential state variables\nna = 0 # Number of algebraic variables\nnu = 1 # Number of inputs\n\ndiscrete_dynamics_colloc = SeeToDee.SimpleColloc(cartpole, Ts, nx, na, nu; n, abstol=1e-10)\nx1_colloc = discrete_dynamics_colloc(x0, u0, p, 0)\n\nusing Test\n@test x1_rk4 ≈ x1_colloc atol=1e-2 # Test the it's roughly the same as the output of RK4","category":"page"},{"location":"","page":"Home","title":"Home","text":"If we benchmark these two methods","category":"page"},{"location":"","page":"Home","title":"Home","text":"@btime $discrete_dynamics_rk($x0, $u0, $p, 0);     # 203.633 ns (0 allocations: 0 bytes)\n@btime $discrete_dynamics_colloc($x0, $u0, $p, 0); # 22.072 μs (80 allocations: 50.23 KiB)","category":"page"},{"location":"","page":"Home","title":"Home","text":"the explicit RK4 method is much faster in this case.","category":"page"},{"location":"#Using-fully-implicit-dynamics","page":"Home","title":"Using fully implicit dynamics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Below, we define the same dynamics as above, but this time in the fully implicit form","category":"page"},{"location":"","page":"Home","title":"Home","text":"0 = F(x x u p t)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This is occasionally useful in order to avoid inverting large coordinate-dependent mass matrices for mechanical systems etc. In the cartpole function, the mass matrix is called H, and it's of size 2×2","category":"page"},{"location":"","page":"Home","title":"Home","text":"function cartpole_implicit(dx, x, u, p, _=0)\n    mc, mp, l, g = 1.0, 0.2, 0.5, 9.81\n\n    q  = x[SA[1, 2]]\n    qd = x[SA[3, 4]]\n\n    s = sin(q[2])\n    c = cos(q[2])\n\n    H = @SMatrix [mc+mp mp*l*c; mp*l*c mp*l^2]\n    C = @SMatrix [0 -mp*qd[2]*l*s; 0 0]\n    G = @SVector [0, mp * g * l * s]\n    B = @SVector [1, 0]\n    Hqdd = (C * qd + G - B * u[1]) # Acceleration times mass matrix H\n    return [qd; -Hqdd] - [dx[SA[1, 2]]; H*dx[SA[3, 4]]] # We multiply H here instead of inverting H like above\nend\n\ndiscrete_dynamics_implicit = SimpleColloc(cartpole_implicit, Ts, nx, na, nu; n, abstol=1e-10, residual=true)\n\nx1_implicit = discrete_dynamics_implicit(x0, u0, p, 0)\n\n@test x1_implicit ≈ x1_colloc atol=1e-9","category":"page"},{"location":"","page":"Home","title":"Home","text":"@btime $discrete_dynamics_implicit($x0, $u0, 0, 0); # 21.911 μs (84 allocations: 50.39 KiB)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For this system, the solve time is almost identical to the explicit collocation case, but for larger systems, the implicit form can be faster.","category":"page"},{"location":"#Using-AdaptiveStep-for-arbitrary-step-sizes","page":"Home","title":"Using AdaptiveStep for arbitrary step sizes","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The AdaptiveStep wrapper allows you to take arbitrary step sizes with any integrator by automatically subdividing large steps:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Create an adaptive wrapper around the RK4 integrator\nadaptive_rk = SeeToDee.AdaptiveStep(discrete_dynamics_rk)\n\n# The effective largest step size (accounting for supersample=2)\n@show adaptive_rk.largest_Ts  # Should be Ts/2 = 0.005\n\n# Take a step that's larger than the base step size\n# This will automatically use supersample=10 internally\nlarge_step = 0.05  # 10x larger than largest_Ts\nx1_adaptive = adaptive_rk(x0, u0, p, 0; Ts=large_step)\n\n# Compare with manual stepping\nx_manual = x0\nfor i in 1:10\n    global x_manual\n    x_manual = discrete_dynamics_rk(x_manual, u0, p, (i-1)*0.005; Ts=0.005)\nend\n\n@test x1_adaptive ≈ x_manual rtol=1e-8  # Should be nearly identical","category":"page"},{"location":"#Using-SwitchingIntegrator-for-conditional-integration","page":"Home","title":"Using SwitchingIntegrator for conditional integration","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The SeeToDee.SwitchingIntegrator allows you to switch between two different integrators based on runtime conditions. This is useful when you want to use a fast integrator in well-behaved regions and a more accurate (but slower) integrator otherwise:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LinearAlgebra\n# Create a fast and an accurate integrator\nfast_integrator = SeeToDee.ForwardEuler(cartpole, Ts; supersample=1)\naccurate_integrator = SeeToDee.Rk4(cartpole, Ts; supersample=3)\n\n# Define a condition: use fast integrator when state norm is small\ncondition = (x, u, p, t) -> norm(x) < 5.0\n\n# Create the switching integrator\nswitching_integrator = SeeToDee.SwitchingIntegrator(\n    fast_integrator,\n    accurate_integrator,\n    condition\n)\n\n# Use it like any other integrator\nx_small = SA[0.1, 0.2, 0.3, 0.4]  # Small state, uses fast integrator\nx1_small = switching_integrator(x_small, u0, p, 0)\n\nx_large = SA[10.0, 10.0, 10.0, 10.0]  # Large state, uses accurate integrator\nx1_large = switching_integrator(x_large, u0, p, 0)","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can also switch based on time, parameters, or any combination:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Time-based switching: fast integrator during transients, accurate in steady-state\ntime_switching = SeeToDee.SwitchingIntegrator(\n    accurate_integrator,\n    fast_integrator,\n    (x, u, p, t) -> t < 1.0  # Use accurate integrator for first second\n)\n\n# Parameter-based switching\nparam_switching = SeeToDee.SwitchingIntegrator(\n    fast_integrator,\n    accurate_integrator,\n    (x, u, p, t) -> p[1] > 0.5  # Switch based on first parameter\n)\nnothing # hide","category":"page"},{"location":"#Simulate-whole-trajectories","page":"Home","title":"Simulate whole trajectories","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Simulation is done by implementing the loop manually, for example (pseudocode)","category":"page"},{"location":"","page":"Home","title":"Home","text":"discrete_dynamics = SeeToDee.Rk4(cartpole, Ts; supersample=2)\n\nx = x0\nX = [x]\nU = []\nfor i = 1:T\n    u = compute_control_input(x)      # State feedback, MPC, etc.\n    x = discrete_dynamics(x, u, p, t) # Propagate state forward one step\n    push!(X, x) # Log data\n    push!(U, u)\nend","category":"page"},{"location":"#Batch-propagation-and-GPU-support","page":"Home","title":"Batch propagation and GPU support","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Using SeeToDee.Rk4, it's possible to propagate a batch of N states forward in time by writing the dynamics to accept matrices x and u where size(x) = (nx, N). No further changes are required. This also works if x, u are GPU arrays, such as those from CUDA.jl. For best performance on the GPU, make sure to construct the Rk4 object using a sample time of type Float32 and make sure that your x, u are also of element type Float32. N has to be rather large for this to be worthwhile. Propagating the state in batches can be useful when implementing, e.g., a particle filter.","category":"page"},{"location":"#Usage-in-the-wild","page":"Home","title":"Usage in the wild","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is used in the following places","category":"page"},{"location":"","page":"Home","title":"Home","text":"DiscretePIDs.jl\nLowLevelParticleFilters.jl, see tutorial.\nODE parameter calibration (video)","category":"page"}]
}
